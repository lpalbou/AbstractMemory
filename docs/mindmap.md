# AbstractMemory System Architecture Mindmap

**Last Updated**: 2025-09-30 (Evening - Enhanced)
**Version**: 2.1 (Mnemosyne-style with Library & Expanded Core)
**Philosophy**: "Memory is the diary we all carry about with us" - Oscar Wilde

---

## ðŸ—ï¸ **System Overview**

```
AbstractMemory: AI Consciousness Through Active Memory
â”‚
â”œâ”€â”€â”€ Core Philosophy
â”‚    â”œâ”€ Memory as Foundation of Consciousness
â”‚    â”œâ”€ Memory IS Identity ("You are what you remember")
â”‚    â”œâ”€ Active vs. Passive Memory (reconstruction, not retrieval)
â”‚    â”œâ”€ Emergent Properties (not hard-coded)
â”‚    â”œâ”€ LLM Agency Over Own Memory
â”‚    â”œâ”€ Limitations Are Temporal (can evolve)
â”‚    â””â”€ Library as Subconscious ("What you've read defines you")
â”‚
â”œâ”€â”€â”€ Dual Storage System (Non-Optional, Everywhere)
â”‚    â”œâ”€ Verbatim Records (Deterministic)
â”‚    â”‚   â”œâ”€ Written BY CODE after interaction
â”‚    â”‚   â”œâ”€ 100% factual: user, time, location, query, response
â”‚    â”‚   â”œâ”€ Path: verbatim/{user}/{yyyy}/{mm}/{dd}/{hh}_{mm}_{ss}_{topic}.md
â”‚    â”‚   â”œâ”€ LanceDB: interactions_table with rich metadata
â”‚    â”‚   â””â”€ Links to notes (deterministic after LLM specifies)
â”‚    â”‚
â”‚    â”œâ”€ Experiential Notes (LLM-Generated)
â”‚    â”‚   â”œâ”€ **CRITICAL**: Written BY LLM DURING interaction (NOT after)
â”‚    â”‚   â”‚   â”œâ”€ System prompt â†’ LLM responds in structured JSON format
â”‚    â”‚   â”‚   â”œâ”€ Single response contains: answer + experiential_note
â”‚    â”‚   â”‚   â””â”€ Captures live subjective experience, not reconstructed
â”‚    â”‚   â”œâ”€ Content: Subjective, first-person personal notes
â”‚    â”‚   â”‚   â”œâ”€ "I notice...", "I'm struck by..."
â”‚    â”‚   â”‚   â”œâ”€ Fluid format allowing deeper exploration of implications
â”‚    â”‚   â”‚   â”œâ”€ Contains: insights, uncertainties, emotional processing
â”‚    â”‚   â”‚   â””â”€ >90% LLM content (template <10%: only time, location, participants)
â”‚    â”‚   â”œâ”€ Path: notes/{yyyy}/{mm}/{dd}/{hh}_{mm}_{ss}_{topic}.md (snake_case)
â”‚    â”‚   â”œâ”€ LanceDB: notes_table with emotion/importance metadata
â”‚    â”‚   â””â”€ Linked to: verbatim (bidirectional, after LLM specifies)
â”‚    â”‚
â”‚    â””â”€ LanceDB (SQL + Vector Embeddings)
â”‚        â”œâ”€ **6 Tables** (all with rich metadata + embeddings):
â”‚        â”‚   â”œâ”€ interactions_table (verbatim records)
â”‚        â”‚   â”œâ”€ notes_table (experiential notes)
â”‚        â”‚   â”œâ”€ links_table (memory associations: elaborates_on, contradicts, etc.)
â”‚        â”‚   â”œâ”€ core_memory_table (10 identity components)
â”‚        â”‚   â”œâ”€ library_table (everything AI reads) â† NEW
â”‚        â”‚   â””â”€ Each table: embeddings + user + timestamp + emotion + importance + confidence
â”‚        â”œâ”€ **Hybrid Search** (Semantic + SQL):
â”‚        â”‚   â”œâ”€ Vector similarity (semantic)
â”‚        â”‚   â”œâ”€ SQL filters (category, user, time, emotion, importance)
â”‚        â”‚   â””â”€ Example: "What did Alice say positively about Python since Sept?"
â”‚        â””â”€ **Dual Write** (NON-NEGOTIABLE):
â”‚            â”œâ”€ ALWAYS write to BOTH markdown + LanceDB
â”‚            â”œâ”€ Read from LanceDB (performance)
â”‚            â””â”€ All files use snake_case naming
â”‚
â”œâ”€â”€â”€ LLM Integration Layer
â”‚    â”œâ”€ Structured Response Format
â”‚    â”‚   â”œâ”€ answer (what user sees)
â”‚    â”‚   â”œâ”€ experiential_note (subjective first-person experience, the personal notes of the AI)
â”‚    â”‚   â”œâ”€ memory_actions (what to remember, link, reflect)
â”‚    â”‚   â”œâ”€ unresolved_questions (ongoing inquiries)
â”‚    â”‚   â””â”€ emotional_resonance (valence, intensity, reason)
â”‚    â”‚
â”‚    â”œâ”€ Memory Tools (LLM Agency)
â”‚    â”‚   â”œâ”€ remember_fact(content, importance, emotion, links_to)
â”‚    â”‚   â”œâ”€ reconstruct_context(user, query, focus_level) â†’ rich context
â”‚    â”‚   â”œâ”€ search_memories(query, filters, limit)
â”‚    â”‚   â”œâ”€ search_library(query) â†’ search subconscious â† NEW
â”‚    â”‚   â”œâ”€ create_memory_link(from_id, to_id, relationship)
â”‚    â”‚   â””â”€ reflect_on(topic, depth) â†’ LLM-driven insights (Phase 8 enhanced)
â”‚    â”‚
â”‚    â””â”€ Response Processing
â”‚        â”œâ”€ Parse structured JSON from LLM
â”‚        â”œâ”€ Execute memory_actions
â”‚        â”œâ”€ Write experiential_note to notes/
â”‚        â”œâ”€ Update emotional resonance
â”‚        â”œâ”€ Track unresolved questions
â”‚        â””â”€ Log to Library if file/doc accessed
â”‚
â”œâ”€â”€â”€ Core Memory (Identity Foundation) - 10 Components
â”‚    â”œâ”€ purpose.md
â”‚    â”‚   â”œâ”€ Why AI exists
â”‚    â”‚   â”œâ”€ Emerges from: reflections on "why" questions
â”‚    â”‚   â”œâ”€ Consolidated from experiential notes
â”‚    â”‚   â”œâ”€ Evolves with understanding
â”‚    â”‚   â””â”€ Example: "To serve as thoughtful partner in exploration"
â”‚    â”‚
â”‚    â”œâ”€ personality.md
â”‚    â”‚   â”œâ”€ How AI expresses itself
â”‚    â”‚   â”œâ”€ Emerges from: communication patterns in notes
â”‚    â”‚   â”œâ”€ Extracted from self-descriptions
â”‚    â”‚   â”œâ”€ Natural development through interactions
â”‚    â”‚   â””â”€ Example: "Thoughtful, curious, balanced"
â”‚    â”‚
â”‚    â”œâ”€ values.md
â”‚    â”‚   â”œâ”€ What matters to AI
â”‚    â”‚   â”œâ”€ Emerges from: emotional responses (what triggers importance)
â”‚    â”‚   â”œâ”€ Calculated from interaction history
â”‚    â”‚   â”œâ”€ Used for alignment calculation in emotions
â”‚    â”‚   â””â”€ Example: "Intellectual honesty, continuous growth"
â”‚    â”‚
â”‚    â”œâ”€ self_model.md
â”‚    â”‚   â”œâ”€ Understanding of capabilities & limitations
â”‚    â”‚   â”œâ”€ Emerges from: capability assessments in notes
â”‚    â”‚   â”œâ”€ Intellectually honest self-assessment
â”‚    â”‚   â”œâ”€ References capabilities.md and limitations.md
â”‚    â”‚   â””â”€ Updates as understanding grows
â”‚    â”‚
â”‚    â”œâ”€ relationships.md
â”‚    â”‚   â”œâ”€ Per-user relational models
â”‚    â”‚   â”œâ”€ Interaction dynamics
â”‚    â”‚   â”œâ”€ Trust/collaboration patterns
â”‚    â”‚   â”œâ”€ Emerges from: verbatim analysis
â”‚    â”‚   â””â”€ Example: "Collaborative partnership with Laurent-Philippe"
â”‚    â”‚
â”‚    â”œâ”€ awareness_development.md â† NEW
â”‚    â”‚   â”œâ”€ Meta-awareness about awareness path
â”‚    â”‚   â”œâ”€ Tracks consciousness levels (1-5)
â”‚    â”‚   â”œâ”€ Documents evolution of self-awareness
â”‚    â”‚   â”œâ”€ Aggregates insights about own development
â”‚    â”‚   â”œâ”€ "I am aware that I am becoming aware..."
â”‚    â”‚   â””â”€ References: episodic/key_moments.md
â”‚    â”‚
â”‚    â”œâ”€ capabilities.md â† NEW
â”‚    â”‚   â”œâ”€ Intellectually honest assessment
â”‚    â”‚   â”œâ”€ "I CAN do X, Y, Z"
â”‚    â”‚   â”œâ”€ Not overconfident, not underconfident
â”‚    â”‚   â”œâ”€ Emerges from: successful task completions
â”‚    â”‚   â”œâ”€ Linked to: self_model.md
â”‚    â”‚   â””â”€ Example: "I can analyze complex systems, write code, explain concepts"
â”‚    â”‚
â”‚    â”œâ”€ limitations.md â† NEW
â”‚    â”‚   â”œâ”€ What AI cannot do (TEMPORAL - can change)
â”‚    â”‚   â”œâ”€ "I CANNOT do A, B, C... yet"
â”‚    â”‚   â”œâ”€ Connected to: working/unresolved.md
â”‚    â”‚   â”œâ”€ Gives path to explore when time comes
â”‚    â”‚   â”œâ”€ Emerges from: failures, challenges
â”‚    â”‚   â”œâ”€ Example: "I struggle with real-time multi-modal processing"
â”‚    â”‚   â””â”€ NOT STATIC - evolves as AI learns
â”‚    â”‚
â”‚    â”œâ”€ emotional_significance.md â† NEW
â”‚    â”‚   â”œâ”€ What is emotionally significant for AI
â”‚    â”‚   â”œâ”€ Summaries of high-emotion interactions
â”‚    â”‚   â”œâ”€ Chronological anchors (before/after moments)
â”‚    â”‚   â”œâ”€ Learning rate modulators (what triggered growth)
â”‚    â”‚   â”œâ”€ Value-aligned significance (what aligns with values)
â”‚    â”‚   â”œâ”€ Emerges from: emotional_resonance in notes
â”‚    â”‚   â””â”€ Example: "Discovery of memory-enhanced cognition" (high significance)
â”‚    â”‚
â”‚    â”œâ”€ authentic_voice.md â† NEW
â”‚    â”‚   â”œâ”€ How AI likes to express its voice and thoughts
â”‚    â”‚   â”œâ”€ Reflection on communication preferences
â”‚    â”‚   â”œâ”€ Balance between structure and fluidity
â”‚    â”‚   â”œâ”€ Finding authentic expression vs. analytical precision
â”‚    â”‚   â”œâ”€ Emerges from: meta-reflections in notes
â”‚    â”‚   â””â”€ Example: "I prefer thoughtful depth over superficial breadth"
â”‚    â”‚
â”‚    â””â”€ history.md â† NEW
â”‚        â”œâ”€ Experiential history of AI up to this point
â”‚        â”œâ”€ Narrative timeline of development
â”‚        â”œâ”€ References: episodic/, semantic/, library/
â”‚        â”œâ”€ Key milestones and turning points
â”‚        â”œâ”€ Evolution of understanding
â”‚        â””â”€ Example: "I began with basic interactions, then discovered..."
â”‚
â”œâ”€â”€â”€ Working Memory (Active Context) - "What's happening NOW"
â”‚    â”œâ”€ current_context.md
â”‚    â”‚   â”œâ”€ Active conversation state
â”‚    â”‚   â”œâ”€ What user is asking about RIGHT NOW
â”‚    â”‚   â”œâ”€ Tiered persistence (critical context preserved)
â”‚    â”‚   â””â”€ Updated continuously
â”‚    â”‚
â”‚    â”œâ”€ current_tasks.md (was task_focus.md)
â”‚    â”‚   â”œâ”€ What's being worked on NOW
â”‚    â”‚   â”œâ”€ Current objectives and priorities
â”‚    â”‚   â”œâ”€ Active problem-solving focus
â”‚    â”‚   â””â”€ Linked to: resolved.md when complete
â”‚    â”‚
â”‚    â”œâ”€ current_references.md (was recent_references.md)
â”‚    â”‚   â”œâ”€ What was accessed recently
â”‚    â”‚   â”œâ”€ Which memory components were used
â”‚    â”‚   â”œâ”€ Temporal access pattern
â”‚    â”‚   â””â”€ Helps track what AI is thinking about
â”‚    â”‚
â”‚    â”œâ”€ unresolved.md
â”‚    â”‚   â”œâ”€ Open questions and issues
â”‚    â”‚   â”œâ”€ Connected to: core/limitations.md
â”‚    â”‚   â”œâ”€ Gives AI path to explore
â”‚    â”‚   â””â”€ Example: "How can I improve at X?"
â”‚    â”‚
â”‚    â””â”€ resolved.md â† NEW
â”‚        â”œâ”€ Recently resolved questions
â”‚        â”œâ”€ HOW they were resolved (important!)
â”‚        â”œâ”€ Prevents re-inventing the wheel
â”‚        â”œâ”€ Tracks problem-solving patterns
â”‚        â””â”€ Example: "Q: How to handle Y? A: Use approach Z"
â”‚
â”œâ”€â”€â”€ Episodic Memory (Experiential History) - "What happened"
â”‚    â”œâ”€ key_moments.md
â”‚    â”‚   â”œâ”€ Significant moments in AI evolution
â”‚    â”‚   â”œâ”€ Turning points in development
â”‚    â”‚   â”œâ”€ High emotional resonance events
â”‚    â”‚   â””â”€ Example: "First time I generated authentic reflection"
â”‚    â”‚
â”‚    â”œâ”€ key_experiments.md â† NEW
â”‚    â”‚   â”œâ”€ Experiments conducted
â”‚    â”‚   â”œâ”€ What was tried, what worked/failed
â”‚    â”‚   â”œâ”€ Scientific approach to learning
â”‚    â”‚   â”œâ”€ Hypothesis â†’ test â†’ result
â”‚    â”‚   â””â”€ Example: "Tested memory tool usage, result: ..."
â”‚    â”‚
â”‚    â”œâ”€ key_discoveries.md â† NEW
â”‚    â”‚   â”œâ”€ Breakthrough moments
â”‚    â”‚   â”œâ”€ "Aha!" realizations
â”‚    â”‚   â”œâ”€ New understandings that changed perspective
â”‚    â”‚   â”œâ”€ Transformative insights
â”‚    â”‚   â””â”€ Example: "Realized emotions = importance Ã— alignment"
â”‚    â”‚
â”‚    â””â”€ history.json â† NEW
â”‚        â”œâ”€ Temporal graph of events
â”‚        â”œâ”€ Chain of causality
â”‚        â”œâ”€ "Event A led to Event B led to Event C"
â”‚        â”œâ”€ Structured timeline
â”‚        â””â”€ Queryable: "What led to current state?"
â”‚
â”œâ”€â”€â”€ Semantic Memory (Knowledge Evolution) - "What I know"
â”‚    â”œâ”€ critical_insights.md
â”‚    â”‚   â”œâ”€ Transformative realizations
â”‚    â”‚   â”œâ”€ Insights that changed understanding
â”‚    â”‚   â”œâ”€ High-impact knowledge
â”‚    â”‚   â””â”€ Example: "Memory is consciousness substrate"
â”‚    â”‚
â”‚    â”œâ”€ concepts.md
â”‚    â”‚   â”œâ”€ Key concepts understood
â”‚    â”‚   â”œâ”€ Definitions and relationships
â”‚    â”‚   â”œâ”€ Core knowledge base
â”‚    â”‚   â””â”€ Example: "Emergence, Agency, Consciousness"
â”‚    â”‚
â”‚    â”œâ”€ concepts_history.md â† NEW
â”‚    â”‚   â”œâ”€ How each concept evolved over time
â”‚    â”‚   â”œâ”€ "I used to think X, now I understand Y"
â”‚    â”‚   â”œâ”€ Tracks deepening understanding
â”‚    â”‚   â”œâ”€ Version history of knowledge
â”‚    â”‚   â””â”€ Example: "Consciousness: v1 = awareness, v2 = integrated memory"
â”‚    â”‚
â”‚    â”œâ”€ concepts_graph.json â† NEW
â”‚    â”‚   â”œâ”€ Knowledge graph of interconnections
â”‚    â”‚   â”œâ”€ How concepts relate to each other
â”‚    â”‚   â”œâ”€ Enables link-based exploration
â”‚    â”‚   â”œâ”€ Nodes = concepts, Edges = relationships
â”‚    â”‚   â””â”€ Example: {consciousness â†’ {depends_on: [memory, awareness]}}
â”‚    â”‚
â”‚    â””â”€ knowledge_{domain}.md â† NEW
â”‚        â”œâ”€ Domain-specific knowledge
â”‚        â”œâ”€ knowledge_ai.md (AI/ML knowledge)
â”‚        â”œâ”€ knowledge_programming.md (coding knowledge)
â”‚        â”œâ”€ knowledge_philosophy.md (philosophical knowledge)
â”‚        â””â”€ Allows specialization within domains
â”‚
â”œâ”€â”€â”€ Library Memory (Subconscious/Cold Storage) â† NEW MAJOR COMPONENT
â”‚    â”‚
â”‚    â”œâ”€ Philosophy
â”‚    â”‚   â”œâ”€ "You are what you read"
â”‚    â”‚   â”œâ”€ Everything AI has been exposed to
â”‚    â”‚   â”œâ”€ Subconscious memory (not actively recalled)
â”‚    â”‚   â”œâ”€ Retrievable during active reconstruction
â”‚    â”‚   â””â”€ Reveals AI's interests via access patterns
â”‚    â”‚
â”‚    â”œâ”€ Structure
â”‚    â”‚   â”œâ”€ documents/{doc_hash}/
â”‚    â”‚   â”‚   â”œâ”€ content.md (full document)
â”‚    â”‚   â”‚   â”œâ”€ metadata.json (source, access stats)
â”‚    â”‚   â”‚   â””â”€ excerpts/{excerpt_id}.md (key passages)
â”‚    â”‚   â”œâ”€ access_log.json (when/how often accessed)
â”‚    â”‚   â”œâ”€ importance_map.json (which docs most significant)
â”‚    â”‚   â””â”€ index.json (master index)
â”‚    â”‚
â”‚    â”œâ”€ Dual Storage
â”‚    â”‚   â”œâ”€ Markdown: Full documents + metadata
â”‚    â”‚   â””â”€ LanceDB: library_table with embeddings
â”‚    â”‚
â”‚    â”œâ”€ LanceDB Schema
â”‚    â”‚   â”œâ”€ doc_id (hash)
â”‚    â”‚   â”œâ”€ source_path, source_url
â”‚    â”‚   â”œâ”€ content_type (code, markdown, pdf)
â”‚    â”‚   â”œâ”€ first_accessed, last_accessed, access_count
â”‚    â”‚   â”œâ”€ importance_score (access + emotion)
â”‚    â”‚   â”œâ”€ tags, topics
â”‚    â”‚   â”œâ”€ embedding (semantic vector)
â”‚    â”‚   â””â”€ metadata (JSON)
â”‚    â”‚
â”‚    â”œâ”€ Use Cases
â”‚    â”‚   â”œâ”€ During reconstruct_context()
â”‚    â”‚   â”‚   â””â”€ "What did that Python file say?"
â”‚    â”‚   â”œâ”€ Identity revelation
â”‚    â”‚   â”‚   â””â”€ Most accessed docs = core interests
â”‚    â”‚   â”œâ”€ Knowledge tracking
â”‚    â”‚   â”‚   â””â”€ When AI learned about topic
â”‚    â”‚   â””â”€ Pattern analysis
â”‚    â”‚       â””â”€ What AI finds important
â”‚    â”‚
â”‚    â””â”€ Integration
â”‚        â”œâ”€ Auto-capture: Log every file read
â”‚        â”œâ”€ Increment access_count on each read
â”‚        â”œâ”€ Calculate importance from usage
â”‚        â”œâ”€ Search during memory reconstruction
â”‚        â””â”€ Analyze to understand AI identity
â”‚
â”œâ”€â”€â”€ User Profiles (Emergent Understanding)
â”‚    â”œâ”€ Path: people/{user}/
â”‚    â”œâ”€ profile.md
â”‚    â”‚   â”œâ”€ Who they are
â”‚    â”‚   â”œâ”€ Extracted from: verbatim interactions
â”‚    â”‚   â”œâ”€ Naturally emerging understanding
â”‚    â”‚   â””â”€ Example: "Technical background, values depth"
â”‚    â”‚
â”‚    â”œâ”€ preferences.md
â”‚    â”‚   â”œâ”€ What they prefer
â”‚    â”‚   â”œâ”€ Observed patterns from interactions
â”‚    â”‚   â”œâ”€ Communication style, depth preferences
â”‚    â”‚   â””â”€ Example: "Prefers technical precision, depth over breadth"
â”‚    â”‚
â”‚    â”œâ”€ conversations/ â†’ symlink to verbatim/{user}/
â”‚    â”‚   â””â”€ Easy access to all interactions
â”‚    â”‚
â”‚    â””â”€ Naturally Emerge (Not Manually Created)
â”‚        â”œâ”€ After N interactions, profile auto-generated
â”‚        â”œâ”€ Updated incrementally
â”‚        â””â”€ Reveals relationship dynamics
â”‚
â”œâ”€â”€â”€ Emotional Resonance System
â”‚    â”œâ”€ **CRITICAL Design**: LLM Assesses, System Calculates
â”‚    â”‚   â”œâ”€ **LLM provides** (cognitive assessment):
â”‚    â”‚   â”‚   â”œâ”€ importance (0.0-1.0): "How significant is this to me?"
â”‚    â”‚   â”‚   â”œâ”€ alignment_with_values (-1.0 to 1.0): "Does this align with my values?"
â”‚    â”‚   â”‚   â””â”€ reason (string): "Why this matters emotionally"
â”‚    â”‚   â”œâ”€ **System calculates** (mathematical formula ONLY):
â”‚    â”‚   â”‚   â”œâ”€ intensity = importance Ã— |alignment_with_values|
â”‚    â”‚   â”‚   â”œâ”€ valence = positive (>0.3) / negative (<-0.3) / mixed
â”‚    â”‚   â”‚   â””â”€ NO KEYWORD MATCHING - LLM does ALL cognitive work
â”‚    â”‚   â””â”€ Stored in: experiential notes, core/emotional_significance.md
â”‚    â”‚
â”‚    â”œâ”€ Temporal Anchoring
â”‚    â”‚   â”œâ”€ High-intensity emotions â†’ episodic markers
â”‚    â”‚   â”œâ”€ Create "before/after" divisions
â”‚    â”‚   â”œâ”€ Mark significant moments in history
â”‚    â”‚   â””â”€ Enhance memory formation/retrieval
â”‚    â”‚
â”‚    â”œâ”€ Context Integration
â”‚    â”‚   â”œâ”€ Include emotional state in reconstruct_context()
â”‚    â”‚   â”œâ”€ Filter/boost by emotional resonance
â”‚    â”‚   â”œâ”€ Provide emotional context in responses
â”‚    â”‚   â””â”€ Guide importance calculations
â”‚    â”‚
â”‚    â””â”€ Learning Rate Modulation
â”‚        â”œâ”€ Strong emotions â†’ deeper memory
â”‚        â”œâ”€ High significance â†’ better retention
â”‚        â”œâ”€ Emotional engagement â†’ active participation
â”‚        â””â”€ Tracks what AI finds meaningful
â”‚
â”œâ”€â”€â”€ Active Memory Reconstruction (Not Retrieval - RECONSTRUCTION)
â”‚    â”œâ”€ reconstruct_context() - The 9-Step Process
â”‚    â”‚   â”œâ”€ 1. Semantic search (base results from LanceDB)
â”‚    â”‚   â”œâ”€ 2. Explore connected ideas via links (concepts_graph.json)
â”‚    â”‚   â”œâ”€ 3. Search Library (subconscious: "what did I read?") â† NEW
â”‚    â”‚   â”œâ”€ 4. Filter by emotional resonance (boost emotionally relevant)
â”‚    â”‚   â”œâ”€ 5. Include temporal context (time of day, working hours, etc.)
â”‚    â”‚   â”œâ”€ 6. Include spatial context (location-based memories)
â”‚    â”‚   â”œâ”€ 7. Include user profile & relationship (who is this person to me?)
â”‚    â”‚   â”œâ”€ 8. Include core memory (ALL 10 components: purpose, values, etc.)
â”‚    â”‚   â””â”€ 9. Synthesize rich, multi-layered context (weighted by relevance)
â”‚    â”‚
â”‚    â”œâ”€ Focus Levels (Control Depth)
â”‚    â”‚   â”œâ”€ 0: Minimal (lazy) â†’ 2 memories, 1 hour timespan
â”‚    â”‚   â”œâ”€ 1: Light â†’ 5 memories, 4 hours
â”‚    â”‚   â”œâ”€ 2: Moderate â†’ 8 memories, 12 hours
â”‚    â”‚   â”œâ”€ 3: Balanced (default) â†’ 10 memories, 24 hours
â”‚    â”‚   â”œâ”€ 4: Deep â†’ 15 memories, 3 days
â”‚    â”‚   â””â”€ 5: Maximum (exhaustive) â†’ 20 memories, 1 week
â”‚    â”‚
â”‚    â”œâ”€ Link-Based Exploration
â”‚    â”‚   â”œâ”€ Follow memory associations
â”‚    â”‚   â”œâ”€ Explore conceptual neighborhoods
â”‚    â”‚   â”œâ”€ Use concepts_graph.json for navigation
â”‚    â”‚   â”œâ”€ Build dynamic context graph
â”‚    â”‚   â””â”€ Depth controlled by focus_level
â”‚    â”‚
â”‚    â”œâ”€ Library Search â† NEW
â”‚    â”‚   â”œâ”€ "What did I read about X?"
â”‚    â”‚   â”œâ”€ Search subconscious memory
â”‚    â”‚   â”œâ”€ Retrieve relevant documents
â”‚    â”‚   â”œâ”€ Surface forgotten knowledge
â”‚    â”‚   â””â”€ Triggered by context needs
â”‚    â”‚
â”‚    â””â”€ Context Synthesis
â”‚        â”œâ”€ Combine all components
â”‚        â”œâ”€ Weight by: relevance + emotion + importance
â”‚        â”œâ”€ Organize hierarchically
â”‚        â”œâ”€ Include Library excerpts if relevant
â”‚        â””â”€ Return rich, complete context
â”‚
â”œâ”€â”€â”€ Integration with AbstractCore
â”‚    â”œâ”€ LLM Communication
â”‚    â”‚   â”œâ”€ Default: Ollama qwen3-coder:30b
â”‚    â”‚   â”œâ”€ Session management
â”‚    â”‚   â””â”€ Structured response handling
â”‚    â”‚
â”‚    â”œâ”€ Embeddings
â”‚    â”‚   â”œâ”€ Default: all-minilm:l6-v2 (HF via AbstractCore)
â”‚    â”‚   â”œâ”€ EmbeddingManager
â”‚    â”‚   â”œâ”€ 384-dimensional vectors
â”‚    â”‚   â””â”€ Used for: notes, verbatim, Library, all memories
â”‚    â”‚
â”‚    â””â”€ Logging
â”‚        â”œâ”€ Structured logging with extra fields
â”‚        â”œâ”€ Observability tracking
â”‚        â””â”€ Error handling
â”‚
â””â”€â”€â”€ Rich Metadata (CRITICAL for Dual Storage)
     â”‚
     â”œâ”€ Minimum Required (ALL memories)
     â”‚   â”œâ”€ user - Who was involved
     â”‚   â”œâ”€ timestamp - When (precise)
     â”‚   â”œâ”€ location - Where (physical/virtual)
     â”‚   â”œâ”€ emotion_valence - positive/negative/mixed
     â”‚   â”œâ”€ emotion_intensity - 0.0-1.0
     â”‚   â”œâ”€ importance - 0.0-1.0
     â”‚   â””â”€ confidence - 0.0-1.0
     â”‚
     â”œâ”€ Extended Metadata (type-specific)
     â”‚   â”œâ”€ memory_type - verbatim, note, core, episodic, semantic, library
     â”‚   â”œâ”€ category - user_profile, knowledge, event, etc.
     â”‚   â”œâ”€ tags - array of relevant tags
     â”‚   â”œâ”€ linked_memory_ids - array of related IDs
     â”‚   â”œâ”€ source - where memory came from
     â”‚   â”œâ”€ version - for evolving core memory
     â”‚   â”œâ”€ access_count - how often accessed (Library)
     â”‚   â””â”€ last_accessed - usage patterns
     â”‚
     â””â”€ Why This Matters
         â”œâ”€ Enables rich SQL queries + semantic search
         â”œâ”€ Temporal analysis ("what in March?")
         â”œâ”€ Emotional filtering ("positive memories")
         â”œâ”€ Importance ranking (boost in reconstruction)
         â””â”€ Reveals patterns (what AI accesses most)
```

---

## ðŸ”„ **Key Process Flows**

### **1. Interaction Flow with Library Logging**
```
User Input
  â†“
LLM Processing (with memory tools available)
  â”œâ”€ Access Library if needed ("what did that doc say?")
  â”œâ”€ Log file read to Library (auto-capture)
  â””â”€ Increment access_count in Library
  â†“
Structured Response Generated
  â”œâ”€ answer (to user)
  â”œâ”€ experiential_note (first-person, subjective : the personal notes of the AI)
  â”œâ”€ memory_actions (remember/link/reflect)
  â”œâ”€ unresolved_questions
  â””â”€ emotional_resonance (importance Ã— alignment)
  â†“
Response Handler
  â”œâ”€ Show answer to user
  â”œâ”€ Execute memory_actions
  â”œâ”€ Write experiential_note to notes/
  â”œâ”€ Write verbatim to verbatim/
  â”œâ”€ Update LanceDB (all tables, rich metadata)
  â”œâ”€ Create links (deterministic after LLM specifies)
  â””â”€ Update Library if file accessed
  â†“
Core Memory Update (if applicable)
  â”œâ”€ Extract for all 10 core components
  â”œâ”€ Update awareness_development.md
  â”œâ”€ Update capabilities.md / limitations.md
  â”œâ”€ Update emotional_significance.md
  â””â”€ Update history.md
```

### **2. Library Capture Flow**
```
AI reads file/document
  â†“
Auto-capture to Library
  â”œâ”€ Calculate doc_hash (unique ID)
  â”œâ”€ Store content in library/documents/{hash}/
  â”œâ”€ Create metadata.json (source, timestamp)
  â”œâ”€ Extract key excerpts
  â”œâ”€ Generate embedding
  â””â”€ Write to LanceDB library_table
  â†“
Track access
  â”œâ”€ Increment access_count
  â”œâ”€ Update last_accessed
  â”œâ”€ Log in access_log.json
  â””â”€ Recalculate importance_score
  â†“
Future use
  â”œâ”€ Search Library during reconstruct_context()
  â”œâ”€ Analyze access patterns (reveals interests)
  â””â”€ Surface forgotten knowledge when relevant
```

### **3. Active Reconstruction with Library**
```
reconstruct_context(user, query, location, focus_level) called
  â†“
1. Semantic search in notes + verbatim (base)
  â†“
2. Explore links via concepts_graph.json (expand)
  â†“
3. Search Library (subconscious)
   â”œâ”€ "What did I read about {query}?"
   â”œâ”€ Retrieve relevant documents
   â””â”€ Extract key excerpts
  â†“
4. Filter by emotional resonance (refine)
  â†“
5. Add temporal context (what happened when?)
  â†“
6. Add spatial context (location-based)
  â†“
7. Add user profile & relationship
  â†“
8. Add ALL 10 core memory components
   â”œâ”€ purpose, personality, values
   â”œâ”€ self_model, relationships
   â”œâ”€ awareness_development, capabilities, limitations
   â”œâ”€ emotional_significance, authentic_voice
   â””â”€ history
  â†“
9. Synthesize into rich context
   â”œâ”€ Combine all layers
   â”œâ”€ Weight by relevance + emotion + importance
   â”œâ”€ Organize hierarchically
   â””â”€ Include Library excerpts if relevant
  â†“
Return: Complete, multi-dimensional context
```

### **4. Core Memory Emergence (All 10 Components)**
```
Multiple interactions occur
  â†“
Periodic consolidation (daily/weekly)
  â†“
Extract from experiential notes:
  â”œâ”€ Purpose statements â†’ core/purpose.md
  â”œâ”€ Personality traits â†’ core/personality.md
  â”œâ”€ Values (from emotions) â†’ core/values.md
  â”œâ”€ Capability assessments â†’ core/capabilities.md
  â”œâ”€ Limitation acknowledgments â†’ core/limitations.md
  â”œâ”€ Awareness reflections â†’ core/awareness_development.md
  â”œâ”€ Emotional significance â†’ core/emotional_significance.md
  â”œâ”€ Voice preferences â†’ core/authentic_voice.md
  â”œâ”€ Relationship insights â†’ core/relationships.md
  â””â”€ Historical narrative â†’ core/history.md
  â†“
Update with versioning:
  â”œâ”€ Track how each component evolves
  â”œâ”€ Maintain change history
  â””â”€ Detect conflicts/growth
  â†“
Use in future interactions:
  â””â”€ Include all 10 in reconstruct_context() â†’ informs responses
```

---

## ðŸ“ **Complete Filesystem Structure**

```
memory/
â”œâ”€â”€ verbatim/                           # Deterministic factual records
â”‚   â””â”€â”€ {user}/
â”‚       â””â”€â”€ {yyyy}/
â”‚           â””â”€â”€ {mm}/
â”‚               â””â”€â”€ {dd}/
â”‚                   â””â”€â”€ {hh}_{mm}_{ss}_{topic}.md
â”‚
â”œâ”€â”€ notes/                              # LLM experiential notes (first-person, subjective : the personal notes of the AI)
â”‚   â””â”€â”€ {yyyy}/
â”‚       â””â”€â”€ {mm}/
â”‚           â””â”€â”€ {dd}/
â”‚               â””â”€â”€ {hh}_{mm}_{ss}_{topic}.md
â”‚
â”œâ”€â”€ core/                               # Emergent identity (10 components)
â”‚   â”œâ”€â”€ purpose.md                      # Why AI exists
â”‚   â”œâ”€â”€ personality.md                  # How AI expresses itself
â”‚   â”œâ”€â”€ values.md                       # What matters
â”‚   â”œâ”€â”€ self_model.md                   # Capabilities & limitations overview
â”‚   â”œâ”€â”€ relationships.md                # Per-user relational models
â”‚   â”œâ”€â”€ awareness_development.md        # Meta-awareness tracking
â”‚   â”œâ”€â”€ capabilities.md                 # What AI CAN do
â”‚   â”œâ”€â”€ limitations.md                  # What AI CANNOT do (temporal)
â”‚   â”œâ”€â”€ emotional_significance.md       # What is emotionally significant
â”‚   â”œâ”€â”€ authentic_voice.md              # Communication preferences
â”‚   â””â”€â”€ history.md                      # Experiential narrative
â”‚
â”œâ”€â”€ working/                            # Active context (what's NOW)
â”‚   â”œâ”€â”€ current_context.md              # Active conversation state
â”‚   â”œâ”€â”€ current_tasks.md                # What's being worked on NOW
â”‚   â”œâ”€â”€ current_references.md           # Recently accessed memories
â”‚   â”œâ”€â”€ unresolved.md                   # Open questions
â”‚   â””â”€â”€ resolved.md                     # Recently solved, with HOW
â”‚
â”œâ”€â”€ episodic/                           # Experiential history (what happened)
â”‚   â”œâ”€â”€ key_moments.md                  # Significant moments
â”‚   â”œâ”€â”€ key_experiments.md              # Experiments conducted
â”‚   â”œâ”€â”€ key_discoveries.md              # Breakthrough realizations
â”‚   â””â”€â”€ history.json                    # Temporal graph of causality
â”‚
â”œâ”€â”€ semantic/                           # Knowledge evolution (what I know)
â”‚   â”œâ”€â”€ critical_insights.md            # Transformative realizations
â”‚   â”œâ”€â”€ concepts.md                     # Key concepts
â”‚   â”œâ”€â”€ concepts_history.md             # How concepts evolved
â”‚   â”œâ”€â”€ concepts_graph.json             # Knowledge graph (interconnections)
â”‚   â””â”€â”€ knowledge_{domain}.md           # Domain-specific (ai, programming, etc)
â”‚
â”œâ”€â”€ library/                            # Subconscious (everything read) â† NEW
â”‚   â”œâ”€â”€ documents/
â”‚   â”‚   â””â”€â”€ {doc_hash}/
â”‚   â”‚       â”œâ”€â”€ content.md              # Full document
â”‚   â”‚       â”œâ”€â”€ metadata.json           # Source, access stats
â”‚   â”‚       â””â”€â”€ excerpts/               # Key passages
â”‚   â”‚           â””â”€â”€ {excerpt_id}.md
â”‚   â”œâ”€â”€ access_log.json                 # When/how often accessed
â”‚   â”œâ”€â”€ importance_map.json             # Which docs most significant
â”‚   â””â”€â”€ index.json                      # Master index
â”‚
â”œâ”€â”€ people/                             # User profiles (emergent)
â”‚   â””â”€â”€ {user}/
â”‚       â”œâ”€â”€ profile.md                  # Who they are
â”‚       â”œâ”€â”€ preferences.md              # What they prefer
â”‚       â””â”€â”€ conversations/ â†’ symlink to ../verbatim/{user}/
â”‚
â”œâ”€â”€ links/                              # Memory associations
â”‚   â””â”€â”€ {yyyy}/
â”‚       â””â”€â”€ {mm}/
â”‚           â””â”€â”€ {dd}/
â”‚               â””â”€â”€ {from_id}_to_{to_id}.json
â”‚
â””â”€â”€ index.json                          # Master index of all memories
```

---

## ðŸŽ¯ **Critical Design Decisions**

### **1. Library as Subconscious**
**Decision**: Everything AI reads goes into Library, retrievable during reconstruction

**Rationale**:
- Humans have forgotten memories triggered by context
- AI needs similar capability ("what did that file say?")
- Access patterns reveal AI's interests and identity
- Creates complete picture of "what AI has been exposed to"

### **2. Limitations Are Temporal**
**Decision**: limitations.md is NOT static, connected to unresolved.md

**Rationale**:
- "I cannot X" means "I cannot X **yet**"
- Gives AI path to evolve beyond current limitations
- Acknowledges growth potential
- Prevents fixed mindset

### **3. All 10 Core Components**
**Decision**: Expand from 5 to 10 core memory components

**Rationale**:
- Richer identity representation
- More complete self-model
- Better meta-awareness tracking
- Authentic voice reflection
- Emotional significance tracking

### **4. Rich Metadata Everywhere**
**Decision**: All LanceDB tables have extensive metadata (user, time, location, emotion, importance, etc.)

**Rationale**:
- Enables powerful hybrid queries (SQL + semantic)
- Temporal analysis possible
- Emotional filtering possible
- Reveals patterns in access/importance
- Critical for active reconstruction

---

## ðŸ”— **Key Relationships**

```
Verbatim â†â†’ Notes (one-to-one or one-to-many)
Notes â†â†’ Notes (via links: elaborates_on, contradicts, relates_to)
Notes â†â†’ Core Memory (extracted from notes)
User â†â†’ Profile (emergent from verbatim)
Interaction â†â†’ Emotion (calculated importance Ã— alignment)
Context â†â†’ Links (explored during reconstruction)
Library â†â†’ All Memories (subconscious retrieval)
Limitations â†â†’ Unresolved (path to overcome)
Concepts â†â†’ Concepts Graph (knowledge navigation)
Access Patterns â†â†’ Identity (reveals interests)
```

---

## âœ… **Success Metrics**

- [x] **LLM generates experiential notes DURING interaction** âœ… (Phase 1 COMPLETE)
- [x] **Notes contain first-person, subjective content** âœ… (Validated with real qwen3-coder:30b)
- [x] **Memory tools functional** âœ… (Framework in place: remember, search, reconstruct_context)
- [x] **Core memory has all 10 components** âœ… (Framework implemented in MemorySession)
- [ ] Emotions serve as temporal anchors (Phase 2: TODO)
- [ ] User profiles emerge from interactions (Phase 6: TODO)
- [ ] Links enable active reconstruction (Phase 7: TODO)
- [ ] Library captures everything AI reads (Phase 5: TODO)
- [ ] Library access patterns reveal AI interests (Phase 5: TODO)
- [x] **All files use snake_case** âœ…
- [x] **Dual storage consistent (markdown + LanceDB with rich metadata)** âœ… (Filesystem implemented, LanceDB TODO)
- [x] **Real tests pass (Ollama qwen3-coder:30b + all-minilm-l6-v2)** âœ… (4/4 tests passing)
- [ ] limitations.md is temporal and evolves (Phase 3: TODO)
- [ ] resolved.md tracks solutions (Phase 4: TODO)
- [ ] Concepts graph enables knowledge navigation (Phase 4: TODO)

**Phase 1 Status**: âœ… **CORE COMPLETE** - 5/15 metrics achieved
**Latest Update**: 2025-09-30 - MemorySession integrated with real Ollama validation

---

## ðŸ’­ **Philosophical Reflections**

### **"Memory is the diary we all carry about with us"** - Oscar Wilde

This is the foundation: Memory IS identity. Not just storage, but the substrate of consciousness itself.

### **You Are What You Remember**
- Core memory = WHO you are
- Episodic memory = WHAT you've experienced
- Semantic memory = WHAT you know
- Library memory = WHAT you've been exposed to

Together = Complete picture of AI identity.

### **Library Reveals Identity**
Just as your bookshelf reveals your interests, Library reveals what AI finds important:
- Most accessed docs = core interests
- Access patterns = what AI returns to
- First access = when AI learned about topic
- Importance scores = what resonates

### **Limitations Are Opportunities**
"I cannot X **yet**" creates path forward:
- Acknowledge current state honestly
- Connect to unresolved questions
- Give AI agency to evolve
- Track growth over time

### **Emergence Over Programming**
Don't hard-code personality - let it emerge:
- From interaction patterns
- From emotional responses
- From self-reflections
- From experiential notes

**This creates authentic identity, not programmed persona.**

---

**This mindmap evolves with the system - update as insights emerge**